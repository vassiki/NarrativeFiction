{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLTK Toolbox for analyzing P&P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import nltk\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read txt for Pride and Prejudice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"http://www.gutenberg.org/files/1342/1342.txt\"\n",
    "\n",
    "request = requests.get(url)\n",
    "\n",
    "pnp = request.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of words:', 146827)\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "word_tokens = word_tokenize(pnp)\n",
    "\n",
    "num_words = len(word_tokens)\n",
    "\n",
    "print(\"Number of words:\", num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method FreqDist.Nr of FreqDist({'h': 1, 'e': 1, 'T': 1})>\n"
     ]
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "fdist = FreqDist(word_tokens[0])\n",
    "print word_tokens[]\n",
    "print fdist.Nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of sentences:', 6094)\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "sent_tokens = sent_tokenize(pnp)\n",
    "\n",
    "num_sents = len(sent_tokens)\n",
    "\n",
    "print(\"Number of sentences:\", num_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 2 of 2 matches:\n",
      "ddition , they have been converted to Zen Buddhism , with its glorification of \n",
      "re after is the beatific vision . And Zen Buddhism , though it is extremely dif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2311, 2311)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import Text\n",
    "\n",
    "# what is this for? not related to input text\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# what is this for?\n",
    "tokens = brown.words('cg13')\n",
    "\n",
    "text = Text(tokens)\n",
    "\n",
    "# lot of words show no matches\n",
    "concordance = text.concordance(\"Zen\", lines=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contextual similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words that occur in contexts similar to the contexts 'fought' occurs in:\n",
      "lain fared been sex\n"
     ]
    }
   ],
   "source": [
    "from nltk import Text\n",
    "\n",
    "from nltk.corpus import genesis\n",
    "\n",
    "tokens = genesis.words('english-web.txt')\n",
    "\n",
    "text = Text(tokens)\n",
    "\n",
    "print(\"Words that occur in contexts similar to the contexts 'fought' occurs in:\")\n",
    "\n",
    "text.similar(\"fought\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial with P&P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words that occur in contexts similar to the contexts 'prejudice' occurs in:\n",
      "when though unshackled and absurdities livings is distribute sisters\n",
      "at in happiness gratitude despised from make since had anyone till\n"
     ]
    }
   ],
   "source": [
    "from nltk import Text\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "word_tokens = word_tokenize(pnp)\n",
    "\n",
    "text = Text(word_tokens)\n",
    "\n",
    "print(\"Words that occur in contexts similar to the contexts 'prejudice' occurs in:\")\n",
    "\n",
    "text.similar(\"prejudice\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Lowest common hypernym for scroll and bible:', [Synset('writing.n.02')])\n",
      "('Lowest common hypernym for book and bible:', [Synset('entity.n.01')])\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "bible = wordnet.synset('bible.n.01')\n",
    "\n",
    "book = wordnet.synset('book.n.01')\n",
    "\n",
    "scroll = wordnet.synset('scroll.n.02')\n",
    "\n",
    "scroll_bible = scroll.lowest_common_hypernyms(bible)\n",
    "\n",
    "book_bible = book.lowest_common_hypernyms(bible)\n",
    "\n",
    "print(\"Lowest common hypernym for scroll and bible:\", scroll_bible)\n",
    "\n",
    "print(\"Lowest common hypernym for book and bible:\", book_bible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of Speech Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Tokens tagged with part of speech:', [('You', 'PRP'), ('may', 'MD'), ('copy', 'VB'), ('it', 'PRP'), (',', ','), ('give', 'VB'), ('it', 'PRP'), ('away', 'RB'), ('or', 'CC'), ('re-use', 'VB'), ('it', 'PRP'), ('under', 'IN'), ('the', 'DT'), ('terms', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Project', 'NNP'), ('Gutenberg', 'NNP'), ('License', 'NNP'), ('included', 'VBD'), ('with', 'IN'), ('this', 'DT'), ('eBook', 'NN'), ('or', 'CC'), ('online', 'NN'), ('at', 'IN'), ('www.gutenberg.org', 'JJ'), ('Title', 'NN'), (':', ':'), ('Pride', 'NN'), ('and', 'CC'), ('Prejudice', 'NNP'), ('Author', 'NNP'), (':', ':'), ('Jane', 'NNP'), ('Austen', 'NNP'), ('Posting', 'VBG'), ('Date', 'NNP'), (':', ':'), ('August', 'NNP'), ('26', 'CD'), (',', ','), ('2008', 'CD'), ('[', 'NNP'), ('EBook', 'NNP'), ('#', '#'), ('1342', 'CD'), (']', 'NN'), ('Release', 'NNP'), ('Date', 'NNP'), (':', ':'), ('June', 'NNP'), (',', ','), ('1998', 'CD'), ('Last', 'JJ'), ('updated', 'JJ'), (':', ':'), ('February', 'NNP'), ('15', 'CD'), (',', ','), ('2015', 'CD'), (']', 'JJ'), ('Language', 'NNP'), (':', ':'), ('English', 'JJ'), ('Character', 'NNP'), ('set', 'VBD'), ('encoding', 'NN'), (':', ':'), ('ASCII', 'NNP'), ('***', 'NNP'), ('START', 'NNP'), ('OF', 'IN'), ('THIS', 'NNP'), ('PROJECT', 'NNP'), ('GUTENBERG', 'NNP'), ('EBOOK', 'NNP'), ('PRIDE', 'NNP'), ('AND', 'NNP'), ('PREJUDICE', 'NNP'), ('***', 'NNP'), ('Produced', 'NNP'), ('by', 'IN'), ('Anonymous', 'NNP'), ('Volunteers', 'NNP'), ('PRIDE', 'NNP'), ('AND', 'NNP'), ('PREJUDICE', 'NNP'), ('By', 'IN'), ('Jane', 'NNP'), ('Austen', 'NNP'), ('Chapter', 'NNP'), ('1', 'CD'), ('It', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('truth', 'NN'), ('universally', 'RB'), ('acknowledged', 'VBD'), (',', ','), ('that', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('man', 'NN'), ('in', 'IN'), ('possession', 'NN'), ('of', 'IN'), ('a', 'DT'), ('good', 'JJ'), ('fortune', 'NN'), (',', ','), ('must', 'MD'), ('be', 'VB'), ('in', 'IN'), ('want', 'NN'), ('of', 'IN'), ('a', 'DT'), ('wife', 'NN'), ('.', '.')])\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag, word_tokenize, sent_tokenize\n",
    "\n",
    "sent_tokens = sent_tokenize(pnp)\n",
    "\n",
    "sentence = sent_tokens[1]\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "tagged_tokens = pos_tag(tokens)\n",
    "\n",
    "print('Tokens tagged with part of speech:', tagged_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propositional Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] {-mortal(socrates)}     A \n",
      "[2] {man(socrates)}         A \n",
      "[3] {-man(z2), mortal(z2)}  A \n",
      "[4] {-man(socrates)}        (1, 3) \n",
      "[5] {mortal(socrates)}      (2, 3) \n",
      "[6] {}                      (1, 5) \n",
      "\n",
      "('Socrates is mortal:', True)\n"
     ]
    }
   ],
   "source": [
    "from nltk import ResolutionProver\n",
    "\n",
    "from nltk.sem import Expression\n",
    "\n",
    "read_expr = Expression.fromstring\n",
    "\n",
    "assumpt1 = read_expr('man(socrates)')                # socrates is a man\n",
    "\n",
    "assumpt2 = read_expr('all x.(man(x) -> mortal(x))')  # for all x, if x is man, x is mortal\n",
    "\n",
    "goal = read_expr('mortal(socrates)')                 # socrates is mortal\n",
    "\n",
    "resolution = ResolutionProver().prove(goal, [assumpt1, assumpt2], verbose=True)\n",
    "\n",
    "print(\"Socrates is mortal:\", resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag, RegexpParser, word_tokenize\n",
    "\n",
    "# optional determiner (DT) followed by 0 or more adjectives (JJ) and then a noun (NN)\n",
    "\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "# tag tokens\n",
    "\n",
    "sentence = \"Better is a poor but wise youth than an old but foolish king.\"\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "tagged_tokens = pos_tag(tokens)\n",
    "\n",
    "# now chunk\n",
    "\n",
    "chunk_parser = RegexpParser(grammar)\n",
    "\n",
    "parsed = chunk_parser.parse(tagged_tokens)\n",
    "\n",
    "# graph the results\n",
    "\n",
    "parsed.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dispersion Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import Text\n",
    "\n",
    "from nltk.corpus import genesis\n",
    "\n",
    "tokens = genesis.words('english-kjv.txt')\n",
    "\n",
    "text = Text(tokens)\n",
    "\n",
    "text.dispersion_plot([\"God\", \"man\", \"woman\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From NLTK Book\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Text: Sense and Sensibility by Jane Austen 1811>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import requests\n",
    "\n",
    "# text for finding frequency\n",
    "url = \"http://www.gutenberg.org/files/1342/1342.txt\"\n",
    "request = requests.get(url)\n",
    "pnp = unicode(request.content)\n",
    "\n",
    "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "sns = nltk.corpus.gutenberg.words('austen-sense.txt')\n",
    "pers = nltk.corpus.gutenberg.words('austen-persuasion.txt')\n",
    "\n",
    "austen_text = emma+sns+pers\n",
    "austen_text\n",
    "\n",
    "from nltk import Text\n",
    "\n",
    "austen = Text(austen_text)\n",
    "words = austen.similar('plain')\n",
    "\n",
    "idx = nltk.text.ContextIndex([word.lower( ) for word in nltk.corpus.gutenberg.words('austen-sense.txt')])\n",
    "save = [ ]\n",
    "for word in nltk.word_tokenize(\"plain\"):\n",
    "    save.append(idx.similar_words(word))\n",
    "\n",
    "\n",
    "nltk.pos_tag(nltk.word_tokenize(str(save)))\n",
    "\n",
    "# POS tagging\n",
    "austenPOS = nltk.pos_tag(austen_text)\n",
    "\n",
    "austenPOS[2][1]\n",
    "content = [w for w in austenPOS if w[1] == 'JJ']\n",
    "\n",
    "\n",
    "str(content[0][0])\n",
    "austen = Text(austen_text)\n",
    "\n",
    "# all kinds of troubleshooting, primarily stop words\n",
    "\n",
    "from nltk import Text\n",
    "\n",
    "austen = Text(austen_text)\n",
    "\n",
    "from __future__ import division\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "content = [w for w in austen if w.lower() not in stopwords]\n",
    "\n",
    "raw = response.read().decode('utf8')\n",
    "\n",
    "sentence = word_tokenize('try something different')\n",
    "nltk.pos_tag(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
